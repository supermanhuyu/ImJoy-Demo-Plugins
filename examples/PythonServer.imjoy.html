<docs lang="markdown">
Describe your plugin here.
</docs>

<config lang="json">
{
  "name": "PythonServer",
  "type": "native-python",
  "version": "0.1.0",
  "api_version": "0.1.2",
  "description": "[TODO: describe this plugin with one sentence.]",
  "tags": [],
  "ui": "",
  "inputs": null,
  "outputs": null,
  "flags": [],
  "icon": "extension",
  "env": "",
  "requirements": [],
  "dependencies": ["supermanhuyu/ImJoy-Demo-Plugins:ResultWindow",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20I.imjoy.html",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20II.imjoy.html",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20III.imjoy.html",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20IV.imjoy.html",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20V.imjoy.html",
  "https://github.com/supermanhuyu/ImJoy-Demo-Plugins/blob/master/examples/Function%20VI.imjoy.html"]
}
</config>

<script lang="python">
import os
import time
import shutil
import random
import numpy as np
from scipy import misc
import tensorflow as tf
from keras.models import load_model
import h5py
os.chdir("./faceid")
import facenet
import detect_face
from timer import Timer
from face import single_detection, single_compare, single_recognition, alive_detection, face_align, face_align_single
model_file = "models/models.pb"
emb_h5 = "models/embeddings.h5"
face_vgg = "models/face_vgg16.h5"
http_server = "https://facefiles.sg-ai.com/"
# http_server = "http://192.168.199.107:8000/"

class ImJoyPlugin():
    def setup(self):
        print('setup in python')

    def run(self, my):
        print('starting server ... ')
        self.class_name = None
        self.emb_arr = None
        self.mean = None
        self.pretrain_init()
        print('pretrain_init finished.')
        api.showStatus('init finished.')

    # 人脸模型预加载
    def pretrain_init(self):
        with tf.Graph().as_default():
            # Load the model
            facenet.load_model(model_file)
            # Get input and output tensors
            self.images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")
            self.embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")
            self.phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")
            sess = tf.Session()
            self.sess = sess
            with sess.as_default():
                self.pnet, self.rnet, self.onet = detect_face.create_mtcnn(sess, None)
            return True

    # 人脸检测
    async def predict(self, list):
    # def predict(self, list):
        res = []
        for item in list:
            # print(item)
            # result_file = facefile_detection(item["filename"], item["path"])
            result_file = single_detection(item["filename"], item["path"], self.pnet, self.rnet, self.onet)
            if result_file:
                res.append({'IOU': random.uniform(0.91, 1), 'fileName': item["filename"], 'url1': http_server + result_file,
                            'message': ''})
            else:
                res.append({'IOU': random.uniform(0.91, 1), 'fileName': item["filename"], 'url1': item["url"],
                            'message': '不存在人脸'})

        print(res)
        return res

    # 1:1 人脸核验
    async def predictII(self, args):
    # def predictII(self, args):
        print(args)
        input_dir = args[0]["path"]
        detect_timer = Timer()
        compare_dirs = os.listdir(input_dir)

        f = h5py.File("models/embeddings.h5", 'r')
        mean = f['mean'][:]
        f.close()

        win = await api.createWindow({
            'name': 'ResultWindow',
            'type': 'ResultWindow',
            'w': 40, 'h': 15,
            'data': {'ID': 0, 'flag': '是', 'time': '0s', 'url1': '', 'url2': ''}})
        wait = None
        for compare_dir in compare_dirs:
            image_files = os.listdir(os.path.join(input_dir, compare_dir))
            detect_timer.tic()
            dist = single_compare(input_dir, compare_dir, image_files, mean,
                                  self.pnet, self.rnet, self.onet,
                                  self.images_placeholder, self.embeddings, self.phase_train_placeholder, self.sess)

            detect_timer.toc()

            if dist < 0.37:
                flag = "是"
            else:
                flag = "否"
            print('ID:', compare_dir, "dist:", dist, "flag:", flag, "time:", detect_timer.diff)
            if wait is not None:
                await wait
            wait = win.run({
                    'function': 'FunctionII',
                    'data': {'ID': compare_dir, 'flag': flag, 'time': detect_timer.diff,
                             'url1': http_server + os.path.join(input_dir, compare_dir, image_files[0]),
                             'url2': http_server + os.path.join(input_dir, compare_dir, image_files[1])}})
        return True

    # 1:n人脸识别 导入底库
    async def importBaseid(self, args):
    # def importBaseid(self, args):
        win = await api.createWindow({
            'name': 'ResultWindow',
            'type': 'ResultWindow',
            'w': 40,
            'h': 15,
            'data': {
                'index': 0,
                'fileName': ''
            }
        })

        base_dir = args[0]["path"]
        h5_embs = "models/embeddings.h5"
        files_list = os.listdir(base_dir)
        if os.path.isdir(os.path.join(base_dir, files_list[0])):
            class_name = files_list
            class_name.sort()
            embs_all = None
            detect_timer = Timer()
            id_sum = len(class_name)
            for index, id_name in enumerate(class_name, 1):
                detect_timer.tic()
                # 每个ID下面的file list
                idx_dir = os.path.join(base_dir, id_name)
                img_list = face_align(idx_dir, self.pnet, self.rnet, self.onet)
                images = np.stack(img_list)
                # Run forward pass to calculate embeddings
                feed_dict = {self.images_placeholder: images, self.phase_train_placeholder: False}
                embs_list = self.sess.run(self.embeddings, feed_dict=feed_dict)
                embs = np.mean(embs_list, axis=0)[np.newaxis, :]

                if embs_all is not None:
                    embs_all = np.append(embs_all, embs, axis=0)
                else:
                    embs_all = embs

                detect_timer.toc()
                print('import ID: {} ,  time cost: {:.3f}s'.format(id_name, detect_timer.diff))
                win.run({'function': 'importBaseid', 'data': {'index': index, 'ID': id_name, 'id_sum': id_sum}})
        elif os.path.isfile(os.path.join(base_dir, files_list[0])):
            # img_list = []
            class_name = []
            embs_all = None
            detect_timer = Timer()
            for idx_name in files_list:
                detect_timer.tic()
                prewhitened = face_align_single(base_dir, idx_name, self.pnet, self.rnet, self.onet)
                # img_list.append(prewhitened)
                id_name = os.path.splitext(idx_name)[0]
                class_name.append(id_name)
                images = np.stack([prewhitened])
                feed_dict = {self.images_placeholder: images, self.phase_train_placeholder: False}
                embs = self.sess.run(self.embeddings, feed_dict=feed_dict)

                if embs_all is not None:
                    embs_all = np.append(embs_all, embs, axis=0)
                else:
                    embs_all = embs

                detect_timer.toc()
                print('import ID: {} ,  time cost: {:.3f}s'.format(id_name, detect_timer.diff))
                win.run({'function': 'importBaseid', 'data': {'index': id_name, 'fileName': idx_name}})

        else:
            print("import base id directory error.")
            return False
        h5_embs_bak = h5_embs.replace("embeddings",
                                      "embeddings_" + time.strftime("%Y%m%d%H%M%S", time.localtime()))
        f = h5py.File(h5_embs_bak, 'w')
        class_arr = [i.encode() for i in class_name]
        f.create_dataset('class_name', data=class_arr)
        f.create_dataset('embeddings', data=embs_all)
        f.create_dataset('mean', data=np.mean(embs_all, axis=0))
        f.close()
        if os.path.exists(h5_embs):
            os.remove(h5_embs)
        shutil.copyfile(h5_embs_bak, h5_embs)

        self.class_name = class_name
        self.emb_arr = embs_all
        self.mean = np.mean(embs_all, axis=0)
        print("success load faceid num: ", len(class_name))
        return True


    # 1:n人脸识别 预测
    async def predictIII(self, args):
    # def predictIII(self, args):
        print(args)
        input_dir = args[0]["path"]
        image_files = os.listdir(input_dir)
        output_dir = "data/result/"
        detect_timer = Timer()

        if self.class_name is not None:
            class_name = self.class_name
            emb_arr = self.emb_arr
            mean = self.mean
        else:
            print("prepare to import embeddings to memery ...")
            f = h5py.File(emb_h5, 'r')
            class_arr = f['class_name'][:]
            class_name = [k.decode() for k in class_arr]
            emb_arr = f['embeddings'][:]
            mean = f['mean'][:]
            f.close()

        win = await api.createWindow({
            'name': 'ResultWindow',
            'type': 'ResultWindow',
            'w': 40, 'h': 15,
            'data': {'fileName': '', 'flag': '是', 'time': '0s', 'message': '', 'url1': ''}
        })
        wait = None

        for img in image_files:
            detect_timer.tic()
            save_img, img_id = single_recognition(input_dir, img, output_dir, emb_arr, class_name, mean,
                                                  self.pnet, self.rnet, self.onet,
                                                  self.images_placeholder, self.embeddings, self.phase_train_placeholder, self.sess)
            detect_timer.toc()
            flag = "是"
            message = ""
            if save_img == "none":
                flag = "否"
                message = "没有人脸"
                save_img = os.path.join(input_dir, img)
            elif img_id == "none":
                flag = "否"
            data_dict = {'fileName': img,
                         'flag': flag,
                         'time': detect_timer.diff,
                         'id': img_id,
                         'url1': http_server+save_img,
                         'message': message}
            print(data_dict)
            if wait is not None:
                await wait
            wait = win.run({'function': 'FunctionIII', 'data': data_dict})
        return True

    # 关键点检测
    async def predictIV(self, args):
    # def predictIV(self, args):
        print(args)

        # win = await api.createWindow({
        #     'name': 'ResultWindow',
        #     'type': 'ResultWindow',
        #     'w': 40, 'h': 15,
        #     'data': {'fileName': '', 'keyPoint': ''}
        # })

        # win.run({'function': 'FunctionIV',
        #          'data': {'fileName': 'cat.jpg', 'keyPoint': '[{x: 1, y: 1}, {x2: 2, y2: 2}]'}})
        return True

    # 活体检测
    async def predictV(self, args):
    # def predictV(self, args):
        print(args)
        input_dir = args[0]["path"]
        model = load_model(face_vgg)
        image_files = os.listdir(input_dir)
        image_files.sort()

        win = await api.createWindow({
            'name': 'ResultWindow',
            'type': 'ResultWindow',
            'w': 40, 'h': 15,
            'data': {'fileName': '', 'flag': '', 'url1': ''}
        })
        wait = None
        for img in image_files:
            flag = alive_detection(os.path.join(input_dir, img), model)

            data_dict = {'fileName': img, 'flag': flag, 'url1': http_server+os.path.join(input_dir, img)}
            print(data_dict)
            if wait is not None:
                await wait
            wait = win.run({'function': 'FunctionV', 'data': data_dict})
        return True

    # 图像质量检测
    async def predictVI(self, args):
        print(args)
        # win = await api.createWindow({
        #     'name': 'ResultWindow',
        #     'type': 'ResultWindow',
        #     'w': 40, 'h': 15,
        #     'data': {'fileName': '', 'message': ''}
        # })
        # i = 1
        # while i <= 25:
        #     win.run({'function': 'FunctionVI', 'data': {'fileName': 'cat.jpg', 'message': '图像模糊,详细描述...'}})
        #     i += 1
        return True


    def exit(self):
        print('aborting servers...')


api.export(ImJoyPlugin())
</script>
